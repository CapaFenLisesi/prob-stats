# Random Variables and Event Probabilities

## Random Variables

Let $Y$ be the result of a fair coin flip.  Not a general coin flip,
but a specific instance of flipping a specific coin at a specific
time.  Defined this way, $Y$ is what's known as a *random variable*,
meaning a variable that takes on different values with different
probabilities.^[Random variables are conventionally written using
upper-case letters to distinguish them from ordinary mathematical
variables which are bound to single values and conventionally written
using lower-case letters.]

Probabilities are scaled between 0% and 100% as in natural language.
If a coin flip is fair, there is a 50% chance the coin lands face up
("heads") and a 50% chance it lands face down ("tails").  For
concreteness and ease of analysis, random variables will be restricted
to numerical values.  For the specific coin flip in question, the
random variable $Y$ will take on the value 1 if the coin lands heads
and the value 0 if it lands tails.


## Events and probability

An outcome such as the coin landing heads is called an *event* in
probability theory.  For our purposes, events will be defined as
conditions on random variables.  For example, $Y = 1$ denotes the
event in which our coin flip lands heads. The functional $\mbox{Pr}[\,
\cdot \,]$ defines the probability of an event.  For example, for our
fair coin toss, the probability of the event of the coin landing heads
is written as

$$
\mbox{Pr}[Y = 1] = 0.5.
$$

The events $Y = 1$ and $Y = 0$ are mutually exclusive in that only one
of them can occur.  They are also exhaustive in that one or the other
has to occur.  In general, the chance of any of a set of mutually
exclusive events occurring is the sum of their probabilities.
Furthermore, the sum of the probability of a sequence of mutually
exclusive and exhaustive events is 100%.  Fairness has $\mbox{Pr}[Y =
0] = 0.5$, and sure enough,

$$
= \mbox{Pr}[Y = 0] + \mbox{Pr}[Y = 1]
= 1.
$$

In this particular case, the event in question is $Y = 1 \,
\mathrm{or} \, Y= 0$.  Events may be put together by logical
conjunction or disjunction.

## Sample spaces and possible worlds

Different values of a random variable represent different ways the
world can be, i.e., a *possible world*.  Even though the coin flip
will have a specific outcome in a given world, we consider other
possible ways the world could have been.  The key to statistical
inference lies in this leap of counterfactual reasoning---considering
that the world may have turned out differently than it actually did.

Without loss of generality, we can think of all of the possible worlds
as being balls in an urn.^[For those who are counting, there will
usually be uncountably many balls in the urn.]  Each ball provides a
list of each random variable and the value it takes on in that world.
The set of all balls is called a *sample space*---it determines the
scope of the random variables in play.^[Notationally, the sample space
is usually written as $\Omega$, the capitalized form of the last
letter in the Greek alphabet.]  One or more of the balls may even
represent the values of the random variables in the "real" world.

Events are represented as a collections of balls in the
urn.^[Formally, an event is a subset of the sample space, $E \subseteq
\Omega$.]  For instance, the event $Y = 0$ of our coin landing tails
is represented by the set of all balls in the urn on which the value 0
is recorded for the variable $Y$.




## More stuff



Random variables can represent unequal odds, such as whether a
roulette ball lands in a red pocket.^[18 out of 38 in a double-zero
wheel.]  They may also represent counts, such as the number of views
of a social media item or the number of points scored by a team in a
competition.  Random variables can also represent continuous
quantities, such as the location from which a shot is taken in a
sporting event or the angle at which a spinner lands after being spun.

Random variables can also be multivariate, such as the result of five
cards drawn from a deck of cards without replacement, or the heights
of the students in next year's introductory statistics class.  They
may also be compound---a sequence of random variables can be used to
represent the distance traveled during the year for each employee of a
company and a random variable can also be used to represent the total
distance traveled by each employee.

## Simulation

*Random number generation.* We will assume that we have a primitive
function `uniform_01_rng()`, which when called, behaves much like it
has a 50% chance of returning 0 and a 50% chance of returning 1.^[Such
functions are implemented using *pseudorandom number generators*,
algorithms which generate a deterministic sequences of values with
many of the properties of random sequences.]  Roughly speaking,

$$
\mathrm{uniform\_01\_rng}()
=
\begin{cases}
0 & \mathrm{with \ a} \ 50\% \ \mathrm{chance}
\\
1 & \mathrm{with \ a} \ 50\% \ \mathrm{chance}
\end{cases}
$$

A simple program to generate a realization of a random coin flip and
assign it to an integer variable `y` could be coded as follows.

```
int y = uniform_01_rng()
print 'y = ' y
```

The variable `y` is declared to be an integer and assigned to the
result of calling the `uniform_01_rng()` function.^[The use of a
lower-case $y$ was not accidental.  The variable $y$ represents an
integer, which is the type of a realization of a random $Y$
representing the outcome of a coin flip.  In code, variables are
written in typewriter font (e.g., `y`), whereas in text they are
written in italics like other mathematical variables (e.g., $y$).]
The print statement outputs the quoted string `y = ` &nbsp; followed
by the value of the variable `y`.  Executing the program might produce
the following output.

```{r}
printf("y = %d", rbinom(1, 1, 0.5))
```


*Simulation and random variables.* The program could be expanded with
a loop to write ten outputs.

```
repeat 10 times:
  print uniform_01_rng() ' '
```

Such a program might produce the following output.

```{r}
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
```

Such a program might represent either

1. ten different simulations of the same random variable $Y$, say
$y^{(1)}, \ldots, y^{(10)}$, with parenthetical superscripts indexing
the simulation, or

1.  a single simulation of ten different random variables,
$Y_1, \ldots, Y_{10}$, say $y_1, \ldots, y_{10}$.

The first situation corresponds to simulating ten different ways the
world might be, whereas the second corresponds to simulating a single
way the world might be.  Multiple simulations of the way the world
might be form the building block of computational statistical
inference, and will be the focus of much of this book.

Running the program five times, we get the following behavior.

```{r}
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
```

Considered as five simulations of ten random variables, $Y_1,
\ldots, Y_{10}$, these simulations would be indexed $y_1^{(1)}, \ldots,
y_{10}^{(1)}$ on the first row up through $y_1^{(5)}, \ldots,
y_{10}^{(5)}$ on the last row.


## Seeding a simulation

Simulations can be made exactly reproducible by setting the
pseudorandom number generator seed.

```
seed_rng(1234)
for (n in 1:5) print uniform_01_rng() ' '
```

Now when we run twice, we get the same sequence of draws
from the pseudorandom number generators.

```{r}
set.seed(1234)
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
set.seed(1234)
for (n in 1:10) { cat(rbinom(1, 1, 0.5)); cat(' ') }
```

Every well-written simulation should allow the seed to be set
manually.

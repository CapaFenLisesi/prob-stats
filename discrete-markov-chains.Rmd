# Discrete Markov Chains

## Random processes

A finite sequence of random variables is said to be a random vector.
An infinite sequence

$$
Y = Y_1, Y_2, \ldots
$$

of random variables is said to be a *random process*.^[We consider
only discrete random processes where the set of indexes is the
counting numbers.]  A trivial example is a sequence of independent
Bernoulli trials in which each $Y_t$ is drawn independently according
to $Y_t \sim \mbox{bernoulli}(\theta)$.^[Such a sequence is called a
*Bernoulli process.*]

In this chapter, we will restrict attention to discrete random
processes in which each of the $Y_t$ is a discrete random variable
taking on the same range of values.


## Finite Markov chains

A random process $Y$ is said to be a *Markov chain* if each element is
generated conditioned on only the previous element, so that

$$
p_{Y_{t + 1} \mid Y_1, \ldots, Y_t}(y_{t + 1} \mid y_1, \ldots, y_t)
\ = \
p_{Y_{t + 1} \mid Y_t}(y_{t + 1} \mid y_t)
$$

holds for all $y_1, \ldots, y_{t + 1}$.  In this chapter, we only
consider Markov chains in which the $Y_t$ are discrete random
variables.  Specifically, we'll resitrct attention to where the values
are integers, i.e., $Y_t \in \mathbb{Z}$.  Many of the Markov chains
we consider are finite, taking up to $N$ distinct values, i.e., $Y_t
\in 1:N$.

The Bernoulli process discussed in the previous section is a trivial
example of a finite Markov chain.  Each value is generated
independently, so $p_{Y_{t+1} \mid Y_t}(y \mid y') = p_{Y_{t+1}}(y)$
for all $y'$.

## Drunkard's walk

The so-called *drunkard's walk* is a non-trivial Markov chain which
starts with value 0 and moves randomly right one step on the number
line with probability $\theta$ and left one step with probability $1 -
\theta$.  The initial value is required to be zero,

$$
p_{Y_1}(y_1) \ = \ 1 \ \mbox{ if } \ y_1 = 0.
$$

Subsequent values are generating with probability $\theta$ of adding
one and probability $1 - \theta$ of subtracting one,

$$
p_{Y_{t+1} \mid Y_t}(y_{t+1} \mid y_t)
\ = \
\begin{cases}
\theta & \mbox{if } \ y_{t + 1} = y_t + 1, \mbox{and}
\\[4pt]
1 - \theta & \mbox{if } \ y_{t + 1} = y_t - 1.
\end{cases}
$$

Another way to formulate the drunkard's walk is by setting $Y_1 = 0$
and setting subsequent values to

$$
Y_{t+1} = Y_t + 2 \times Z_t - 1.
$$

where $Z_t \sim \mbox{bernoulli}(\theta).$ Formulated this way, the
drunkard's walk $Y$ is a transform of the Bernoulli process $Z$.  We
can simulate drunkard's walks for $\theta = 0.5$ and $\theta = 0.6$
and see the trend over time.

```
y[1] = 0
for (m in 2:M)
  z[m] = bernoulli_rng(theta)
  y[m] = y[m - 1] + (z[m] ? 1 : -1)
```

We'll simulate from both processes for $M = 1000$ steps and plot.

```{r fig.cap = "Drunkard's walks of 10,000 steps with equal chance of going left or right (blue) versus a sixty percent chance of going left (red).  The dotted line is drawn at the starting point. As time progresses, the biased random walk drifts further and further from its starting point."}

set.seed(1234)
M <- 10000
z1 <- rbinom(M, 1, 0.5)
z2 <- rbinom(M, 1, 0.6)
y1 <- cumsum(2 * z1 - 1)
y2 <- cumsum(2 * z2 - 1)

drunkards_df <-
  data.frame(x = c(1:M, 1:M),
             y = c(y1, y2),
             drunkard = c(rep("50% up / 50% down", M),
                          rep("60% up / 40% down", M)))

drunkards_plot <-
  ggplot(drunkards_df,
         aes(x = x, y = y, group = drunkard)) +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dotted") +
  facet_wrap(. ~ drunkard) +
  scale_x_log10(breaks = c(1, 10, 100, 1000, 10000)) +
  xlab("time") +
  ylab("position") +
  ggtheme_tufte() +
  theme(panel.spacing.x = unit(4, "lines"))
drunkards_plot
```

For the balanced drunkard, the expected drift per step is zero as
there is equal chance of going in either direction. After 10\,000
steps, the expected position of the balanced drunkard remains the
origin.^[Contrary to common language usage, the expected position
being the origin after $10\,000$ steps does not imply that we should
expect the drunkard to be at the origin. It is in fact very unlikely
that the drunkard is at the origin after $10\,000$ steps, as it
requires exactly $5\,000$ upward steps, the probability of which is
$\mbox{binomial}(5\,000 \mid 10\,000, 0.5) = 0.008.$] For the
unbalanced drunkard, the expected drift per step is $0.6 \times 1 +
0.4 \times -1 = 0.2$. Thus after 10\,000 steps, the drunkard's
expected position is $0.2 \times 10\,000 = 2\,000.$

## Fish in the stream

Suppose a person is ice fishing for perch and pike, and notes that if
they catch a perch, it is 95% likely that the next fish they catch is
a perch, whereas if they catch a pike, it is 20% likely the next fish
they catch is a pike.^[This is a thinly reskinned version of the
classic exercise involving cars and trucks from Ross, S.M.,
2014. *Introduction to Probability Models.* Tenth edition. Academic
Press. Exercise 30, page 279.] We'll treat the sequence of fish types
as a random process $Y = Y_1, Y_2, \ldots$ with values

$$
Y_t \ = \
\begin{cases}
1 & \mbox{if fish $t$ is a pike, and}
\\[4pt]
2 & \mbox{if fish $t$ is a perch.}
\end{cases}
$$

The sequence $Y$ forms a Markov chain with transition probabilities

$$
\begin{array}{rcl}
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 1] & = & 0.20
\\[4pt]
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 2] & = & 0.05
\end{array}
$$

The easiest way to visual a Markov chain with only a few states is as
a state transition diagram.  In the case of the pike and perch, the
transition diagram is as follows.

```{r, engine="tikz", fig.ext="pdf", out.width="35%", fig.cap="State diagram for finite Markov chain generating sequences of fishes. The last fish observed determines the current state and the arrows indicate transition probabilities to the next fish observed."}
\begin{tikzpicture}[->, auto, node distance=2cm, font=\footnotesize]
\node[circle,draw,semithick] (A) {1:pike};
\node[circle,draw,semithick] (B) [right of=A] {2:perch};
\path (A) edge [bend left] node {0.80} (B);
\path (B) edge [bend left] node {0.05} (A);
\path (A) edge [loop above] node {0.20} (A);
\path (B) edge [loop above] node {0.95} (B);
\end{tikzpicture}
```

Like all such transition graphs, the probabilities on the edges going
out of a node must sum to one.

Let's simulate some fishing. The approach is the same as that of the
drunkard's walk, only now we will report the overall proportion of
pike.^[With some sleight of hand here for compatiblity with Bernoulli
variates and to facilitate computing proportions, we have recoded
perch as having value 0 rather than 2.] We will start with a random
fish drawn according to $\mbox{bernoulli(1/2)}$.

```
y[1] = bernoulli_rng(0.5)
for (t in 2:T)
  y[t] = bernoulli_rng(y[t - 1] = 1 ? 0.2 : 0.05)
print 'simulated proportion of pike = ' sum(y) / M
```

Now let's assume the fish are really running, and run a few simulated
chains until $T = 10\,000$.

```{r}
set.seed(1234)
T <- 10000
y <- rep(NA, M)
for (k in 1:5) {
  y[1] <- rbinom(1, 1, 0.5)
  for (t in 2:T) {
    y[t] <- rbinom(1, 1, ifelse(y[t - 1] == 1, 0.2, 0.05))
  }
  printf("simulated proportion of pike = %4.3f\n", sum(y) / T)
}
```

The proportion of pike is roughly 0.06.


## Gambler's Ruin

Another classic problem which may be understood in the context of a
discrete Markov chain is the gambler's ruin. Suppose a gambler sits
down to bet with a pile of $N$ chips and is playing a game which costs
one chip to play and returns one chip with a probability of
$\theta$.^[The original formulation of the problem, involving two
gamblers playing each other with finite stakes, was analyzed in
Christiaan Huygens. 1657. *Van Rekeningh in Spelen van Geluck.* Here
we assume one player is the bank with an unlimited stake.] The gambler
is not allowed to go into debt, so if the gambler's fortune ever sinks
to zero, it remains that way in perpetuity. The results of the bets at
times $t = 1, 2, \ldots$ can be modeled as an independent and
identically distributed random process $Z = Z_1, Z_2, \ldots$ with

$$
Z_t \sim \mbox{bernoulli}(\theta).
$$

As usual, a successful bet is represented by $Z_t = 1$ and an
unsuccessful one by $Z_t = 0$.  The gambler's fortune can now be
defined recursively as a time series $Y = Y_1, Y_2,
\ldots$ in which the initial value is given by

$$
Y_1 = N
$$

with subsequent values defined recursively by

$$
Y_{n + 1}
\ = \
\begin{cases}
0 & \mbox{if} \ Y_n = 0, \ \mbox{and}
\\[4pt]
Y_n + Z_n & \mbox{if} \ Y_n > 0.
\end{cases}
$$

Broken down into the language of Markov chains, we have an initial
distribution concentrating all of its mass at the single point $N$,
with mass function

$$
p_{Y_1}(N) = 1.
$$

Each subsequent variable's probability mass function is given by

$$
p_{Y_{t + 1} \mid Y_t}(y_{t + 1} \mid y_t)
\ = \
\begin{cases}
\theta & \mbox{if} \ y_{t + 1} = y_t + 1
\\[4pt]
1 - \theta & \mbox{if} \ y_{t + 1} = y_t - 1.
\end{cases}
$$

These mass functions are all identical in that $p_{Y_{t+n+1} \mid Y_{t
+ n}} = p_{Y_{t + 1} \mid Y_t}.$  In other words, $Y$ is a
time-homogeneous Markov chain.

We are interested in two questions pertaining to the gambler. First,
what is their expected fortune at each time $t$? Second, what is the
probability that they have fortune zero at time $t$.^[A gambler whose
fortune goes to zero is said to be *ruined.*]  Both of these
calculations have simple simulation-based estimates.

Let's start with expected fortune and look out $T = 100$ steps.
Suppose the chance of success on any given bet is $\theta$ and their
initial fortune is $N$. The simulation of the gambler's fortune is
just a straightforward coding of the time series.

```
y[1] = N
for (t in 2:T)
  z[t] = bernoulli_rng(theta)
  y[t] = y[t - 1] + (z[t] ? 1 : -1)
```

Now if we simulate that entire process $M$ times, we can calculate
the expected fortune as an average at each time $t \in 1:T$.

```
for (m in 1:M)
  y(m)[t] = N
  for (t in 2:T)
    z(m)[t] = bernoulli_rng(theta)
    y(m)[t] = y(m)[t - 1] + (z[t] ? 1 : -1)
for (t in 1:T)
  expected_fortune[t] = mean(y(1:M)[t])
```

Let's run $M = 10\,000$ simulations for $T = 50$ starting with a stake
of $N = 5$ with several values of $\theta$ and plot the expected
fortunes.

```{r fig.cap = "Expected returns for gambler starting with stake $N$ and having a $\\theta$ chance at each time point of increasing their fortune by 1 and a $1 - \\theta$ chance of reducing their fortune by 1.  The horizontal dotted line is at the initial fortune and the dashed line is at zero."}

set.seed(1234)
N <- 5
T <- 50
M <- 10000
Theta <- c(0.4, 0.5, 0.6)

df_ruin <- data.frame(x = c(), y = c(), theta = c())
for (theta in Theta) {
  y <- matrix(NA, M, T)
  for (m in 1:M) {
    y[m, 1] <- N
    for (t in 2:T) {
      if (y[m, t - 1] == 0) {
        y[m, t] <- 0
      } else {
        y[m, t] <- y[m, t - 1] + ifelse(rbinom(1, 1, theta), 1, -1)
      }
    }
  }
  expected_fortune <- rep(NA, T)
  for (t in 1:T) {
    expected_fortune[t] <- mean(y[1:M, t])
  }
  df_ruin <- rbind(df_ruin,
                   data.frame(x = 1:T,  y = expected_fortune,
                              theta = rep(paste("theta = ", theta), T)))
}

plot_ruin <-
  ggplot(df_ruin, aes(x = x, y = y, group = theta)) +
  geom_line() +
  geom_hline(yintercept = 5, linetype = 'dotted', size = 0.5) +
  geom_hline(yintercept = 0, linetype = 'dashed', size = 0.5) +
  facet_wrap(. ~ theta) +
  scale_x_continuous(breaks = c(1, 25, 50)) +
  scale_y_continuous(breaks = c(0, 5, 10, 15)) +
  xlab("time") +
  ylab("expected fortune") +
  ggtheme_tufte() +
  theme(panel.spacing.x = unit(4, "lines"))
plot_ruin
```

Next, we'll tackle the problem of estimating the probability that a
gambler has been run out of money at time $t$. In symbols, we are
going to use simulations $y^{(1)}, \ldots, y^{(M)}$ of the gambler's
time series,

$$
\begin{array}{rcl}
\mbox{Pr}[Y_t = 0]
& = &
\mathbb{E}\left[ \mathrm{I}\left[ Y_t = 0 \right] \right].
\\[6pt]
& \approx &
\displaystyle
\frac{1}{M} \sum_{m = 1}^M \, \mathrm{I}\left[ y_t^{(m)} = 0 \right].
\end{array}
$$

This last term can be directly calculated by adding the indicator
variables to the calculations before.

```
for (m in 1:M)
  y(m)[t] = N
  for (t in 2:T)
    z(m)[t] = bernoulli_rng(theta)
    y(m)[t] = y(m)[t - 1] + (z[t] ? 1 : -1)
    ruined(m)[t] = (y(m)[t] == 0)
for (t in 1:T)
  estimated_pr_ruin[t] = mean(ruined(1:M)[t])
```

So let's run that and plot the probability of ruin for the same three
choices of $\theta$, using $M = 5\,000$ simulations.  But this time,
we'll run for $T = 200$ time steps.

```{r fig.cap = 'Probability of running out of money for a gambler starting with stake $N$ and having a $\\theta$ chance at each time point of increasing their fortune by 1 and a $1 - \\theta$ chance of reducing their fortune by 1.  The horizontal dotted line is at 100%.'}

set.seed(1234)
N <- 5
T <- 200
M <- 5000
Theta <- c(0.4, 0.5, 0.6)

df_expect_ruin <- data.frame(x = c(), y = c(), theta = c())
for (theta in Theta) {
  y <- matrix(NA, M, T)
  for (m in 1:M) {
    y[m, 1] <- N
    for (t in 2:T) {
      if (y[m, t - 1] == 0) {
        y[m, t] <- 0
      } else {
        y[m, t] <- y[m, t - 1] + ifelse(rbinom(1, 1, theta), 1, -1)
      }
    }
  }
  pr_ruin <- rep(NA, T)
  for (t in 1:T) {
    pr_ruin[t] <- mean(y[1:M, t] == 0)
  }
  df_expect_ruin <-
    rbind(df_expect_ruin,
          data.frame(x = 1:T,  y = pr_ruin,
                     theta = rep(paste("theta = ", theta), T)))
}

plot_expect_ruin <-
  ggplot(df_expect_ruin, aes(x = x, y = y, group = theta)) +
  geom_line() +
  geom_hline(yintercept = 1, linetype = 'dotted', size = 0.5) +
  facet_wrap(. ~ theta) +
  scale_x_continuous(breaks = c(1, 100, 200)) +
  scale_y_continuous(lim = c(0, 1),
                     breaks = c(0, 0.25, 0.5, 0.75, 1),
		     labels = c("0", "1/4", "1/2", "3/4", "1")) +
  xlab("time") +
  ylab("probability of ruin") +
  ggtheme_tufte() +
  theme(panel.spacing.x = unit(4, "lines"))
plot_expect_ruin
```

Even in a fair game, after 50 bets, there's nearly a 50% chance that
a gambler starting with a stake of 5 is ruined; this probabiltiy goes
up to nearly 75% after 200 bets.

## Ehrenfest's Urns

Suppose we have two urns, with a total of $N$ balls distributed
between them. At each time step, a ball is chosen uniformly at random
from among the balls in both urns and moved to the other urn.^[This
model was originally introduced as an example of entropy and
equilibrium in P. Ehrenfest and T. Ehrenfest. 1906. Über eine Aufgabe
aus der Wahrscheinlichkeitsrechnung, die mit der kinetischen Deutung
der Entropievermehrung zusammenhängt.
*Mathematisch-Naturwissenschaftliche Blätter* No. 11 and 12.]

The process defines a Markov chain $Y$ where transitions are governed
by

$$
p_{Y_{t+1} \mid Y_t}(y_{t+1} \mid y_t)
\ = \
\begin{cases}
\displaystyle \frac{y_t}{N}
& \mbox{if } \ y_{t + 1} = y_t - 1, \ \mbox{and}
\\[6pt]
\displaystyle 1 - \frac{y_t}{N}
& \mbox{if } \ y_{t + 1} = y_t + 1.
\end{cases}
$$

The transition probabilities make sure that the value of $Y_t$ remains
between 0 and $N$.  For example,

$$
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 0] = 1
$$

because $1 - \frac{y_t}{N} = 1$. Similarly, if $Y_t = N$, then
$Y_{t+1} = N - 1$.

What happens to the distibution of $Y_t$ long term? It's easy to
compute by simulation of a single long chain:^[We've used a function
borrowed from R here called `table`, defined by $$\mbox{table}(y, A,
B)[n] = \sum_{t=1}^T \mbox{I}[y_t = n]$$ for $n \in A:B$. For example, if $$y =
(0, 1, 2, 1, 1, 3, 2, 2, 1),$$ then $$\mbox{table}(y, 0, 4) = (1, 4,
3, 1, 0),$$ because there is one 0, four 1s, three 2s, a single 3, and
no 4s among the values of $y$.]

```
y[1] = floor(N / 2)
for (t in 2:T)
  z[t] = bernoulli_rng(y[t - 1] / N)
  y[t] = y[t - 1] + (z[t] ? -1 : +1)
p_Y_t_hat = table(y, 0, N) / T
```

Let's run that with $N = 10$ and $T = 100\,000$ and display the
results as a bar plot.

```{r fig.cap = 'Long-term distribution of number of balls in the first urn of the Ehrenfest model in which $N$ balls are distributed between two urns, then at each time step, a ball is chosen uniformly at random move to the other urn.  The simulation is based on total of $T = 100\\,000$ steps with $N = 10$ balls, starting with 5 balls in the first urn. The points on the top of the bars are positioned at the mass defined by the binomial distribution, $\\mbox{binomial}(Y_t \\mid 10, 0.5)$.'}

set.seed(1234)
N <- 10
T <- 1e5
y <- rep(NA, T)
y[1] <- 5
for (t in 2:T) {
  z_t = rbinom(1, 1, y[t - 1] / N)
  y[t] <- y[t - 1] + ifelse(z_t, -1, 1)
}
# p_Y_t_hat = table(y) / T

ehrenfest_df <- data.frame(x = 1:T, y = y)

ehrenfest_plot <-
  ggplot(ehrenfest_df, aes(y)) +
  geom_bar(color = 'black', fill = '#ffffe8', size = 0.2) +
  geom_point(data = data.frame(x = 0:10, y = T * dbinom(0:10, 10, 0.5)),
             aes(x = x, y = y),
	     size = 3, alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10)) +
  scale_y_continuous(breaks = (0:5) * 5000, labels = (0:5) * 0.05) +
  xlab(expression(Y[t])) +
  ylab("proportion") +
  ggtheme_tufte()
ehrenfest_plot
```

The distribution of $Y_t$ values is the binomial distribution, as
shown by the agreement between the points (the binomial probability
mass function) and the bars (the empirical proportion $Y_t$ spent in
each state).^[In the Markov chain Monte Carlo chapter later in the
book, we will see how to construct a Markov chain whose long-term
frequency distribution matches any given target distribution.]


## Page Rank and the random surfer

Pagerank,^[Page, L., Brin, S., Motwani, R. and Winograd, T., 1999. The
PageRank citation ranking: Bringing order to the web. Stanford InfoLab
Technical Report. Section 2.5 Random Surfer Model.] the innovation
behind the original Google search engine ranking system, can be
modeled in terms of a random web surfer whose behavior determines a
Markov chain.  The web is modeled as a set of pages, each of which has
a set of outgoing links to other pages.  When viewing a particular
page, our random surfer chooses the next page to visit by

* if the current page has outgoing links, then with probability
$\lambda$, choose the next page uniformly at random among the outgoing
links,

* otherwise (with probability $1 - \lambda$), choose the next page to
visit uniformly at random among all web pages.

Translating this into the language of random variables, let $Y = Y_1,
Y_2, \ldots$ be the sequence of web pages visited. Our goal now is to
define the transition function probabilistically so that we may
simulate the random surfer. Let $L_i \subseteq 1:N$ be the set of
outgoing links from page $i$; each page may have any number of
outgoing links from 0 to $N$.

The process $Y$ is most easily described in terms of an auxiliary
process $Z = Z_1, Z_2, \ldots$ where $Z_t$ represents

the decision whether to jump to a link from the current page. We
define $Z$ by setting $Z_t = 0$ if the page $Y_t$ has no
outgoing links, and otherwise setting

$$
Z_t \sim \mbox{bernoulli}(\lambda).
$$

If $Z_t = 1$, we can generate $Y_{t+1}$ uniformly from the links
$L_{Y_t}$ from page $Y_t$,

$$
Y_{t + 1} \sim \mbox{uniform}\left( L_{Y_t} \right).
$$

If $Z_t = 0$, we simply choose a web page uniformly at random from
among all $N$ pages,

$$
Y_{t+1} \sim \mbox{uniform}(1:N).
$$

This sequence is easy to simulate with `L[n]` denoting the outgoing
links from page `n`.  We start from a page `y[1]` chosen uniformly at
random among all the pages.  Then we just simulate subsequent pages
according to the process described above.

```
y[1] <- uniform_rng(1:N)
for (t in 2:T)
  last_page = y[t - 1]
  out_links = L[last_page]
  z[t] <- empty(out_links) ? 0 : bernoulli_rng(lambda)
  y[t] <- uniform(z[t] ? out_links : (1:N))
```

Suppose we have the following graph.

```{r, engine="tikz", fig.ext="pdf", out.width="50%", fig.cap="A simplified web.  Each node represents a web page and each edge is a directed link from one page to another web page."}
\begin{tikzpicture}[->, auto, node distance=2cm, font=\footnotesize]
\node[circle,draw,semithick] (A) {1};
\node[circle,draw,semithick] (B) [above right of=A] {2};
\node[circle,draw,semithick] (C) [below left of=A] {3};
\node[circle,draw,semithick] (D) [below right of=A] {4};
\node[circle,draw,semithick] (E) [right of=D] {5};
\node[circle,draw,semithick] (F) [below left of=C] {6};
\node[circle,draw,semithick] (G) [below of=C] {7};
\node[circle,draw,semithick] (H) [below right of=C] {8};
\node[circle,draw,semithick] (I) [below of=G] {9};
\node[circle,draw,semithick] (J) [below of=H] {10};
\node[circle,draw,semithick] (K) [below of=D] {11};
\node[circle,draw,semithick] (L) [below right of=D] {12};
\path (A) edge [bend left] node {} (B);
\path (B) edge [bend left] node {} (A);
\path (C) edge [] node {} (A);
\path (A) edge [bend left] node {} (D);
\path (D) edge [bend left] node {} (A);
\path (F) edge [] node {} (C);
\path (G) edge [] node {} (C);
\path (H) edge [] node {} (C);
\path (G) edge [] node {} (I);
\path (J) edge [] node {} (H);
\path (D) edge [] node {} (K);
\path (D) edge [] node {} (L);
\end{tikzpicture}
```

We can simulate $T = 100\,000$ page visits using the algorithm shown
above and display the proportion of time spent on each page.

```{r fig.cap = "Proportion of time spent on each page by a random surfer taking $T = 100\\,000$ page views starting from a random page with a web structured as in the previous diagram."}
L = matrix(0, 12, 12)
L[1, c(2, 4)] = 1
L[2, c(1)] = 1
L[3, c(1)] = 1
L[4, c(1, 11, 12)] = 1
L[5, c()] = 1
L[6, c(3)] = 1
L[7, c(3, 9)] = 1
L[8, c(3)] = 1
L[9, c()] = 1
L[10, c(8)] = 1
L[11, c()] = 1
L[12, c()] = 1

lambda <- 0.90
theta <- matrix(NA, 12, 12)
for (i in 1:12) {
  if (sum(L[i, ]) == 0) {
    theta[i, ] <- rep(1/12, 12)
  } else {
    theta[i, ] <- lambda * L[i, ] / sum(L[i, ]) +
                  (1 - lambda) * rep(1 / 12, 12)
  }
}

set.seed(1234)
T <- 1e5
y <- rep(NA, T)
y[1] <- sample(1:12, 1)
for (t in 2:T) {
  y[t] <- sample(1:12, 1, prob = theta[y[t - 1], ])
}

visited = table(y)

pagerank_df <- data.frame(x = 1:T, y = y)

pagerank_plot <-
  ggplot(pagerank_df, aes(y)) +
  geom_bar(color = 'black', fill = '#ffffe8', size = 0.2) +
  scale_x_continuous(breaks = 1:12) +
  scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3) * T,
                     labels = c(0, 0.1, 0.2, 0.3)) +
  xlab("page") +
  ylab("rank (proportion of time on page)") +
  ggtheme_tufte()
pagerank_plot
```

Page 1 is the most central hub. Pages 5, 6, 7, and 10 have no links
coming into them and can only be visited by random chance, so all
should have the same chance of being visited by the random surfer.
Pages 11 and 12 are symmetric, and indeed have the same probability.
There is a slight difference between the views of page 9 and 10 in
that it possible ot get to 9 from 7, but 10 is only visited by chance.


## Queueing

Suppose we have a checkout line at a store (that is open 24 hours a
day, 7 days a week) and a single clerk. The store has a queue, where
customers line up for service. The queue begins empty. Each hour a
random number of customers arrive and a random number of customers are
served.  Unserved customers remain in the queue until they are served.

To make this concrete, suppose we let $U_t \in 0, 1, \ldots$ be the
number of customers that arrive during hour $t$ and that it has a
binomial distribution,

$$
U_t \sim \mbox{binomial}(1000, 0.005).
$$

Just to provide some idea of what this looks like, here are 20
simulated values,

```{r}
M <- 20
y <- rbinom(M, 1000, 0.005)
for (m in 1:M)
  printf("%2.0f ", y[m])
```

We can think of this as 1000 potential customers, each of which has a
half percent chance of deciding to go to the store any hour. If we
repeat, the mean number of arrivals is 5 and the standard deviation is
2.2.

Let's suppose that a cleark can serve up to $V_t$ customers per hour,
determined by the clerk's rate $\phi$,

$$
V_t \sim \mbox{binomial}(1000, \phi).
$$

If $\phi < 0.005,$ there is likely to be trouble.  The clerk
won't be able to keep up on average.

The simulation code just follows the definitions.

```
queue[1] = 0
for (t in 2:T)
  arrive[t] = binomial_rng(1000, 0.005)
  serve[t] = binomial_rng(1000, phi)
  queue[t] = max(0, queue[t - 1] + arrive[t] - serve[t])
```

The `max(0, ...)` is to make sure the queue never gets negative. If
the number served is greater than the total number of arrivals and
customers in the queue, the queue starts empty the next time step.

Let's try different values of $\phi$, the average server rate, and
plot two weeks of service.^[$24 \mbox{hours/day} \ \times 14 \
\mbox{days} = 336 \mbox{hours}$]

```{r fig.cap = 'Multiple simulations of queue size versus time for a queue with $\\mbox{binomial}(1000, 0.005)$ customers arriving per hour (an average of 5), and a maximum of $\\mbox{binomial}(1000, \\phi)$ customers served per hour, plotted for various $\\phi$ (as indicated in the row labels).'}

queue_df <- data.frame(t = c(), queue = c(), run = c(), phi = c())

set.seed(1234)
T <- 14 * 24
run <- 1
queue <- rep(NA, T)
for (m in 1:50) {
  for (phi in c(0.005, 0.0055, 0.006, 0.01)) {
    queue[1] <- 0
    for (t in 2:T) {
      arrived <- rbinom(1, 1000, 0.005)
      served <- rbinom(1, 1000, phi)
      queue[t] <- max(0, queue[t - 1] + arrived - served)
    }
    queue_df <-
      rbind(queue_df,
            data.frame(t = 1:T, queue = queue,
                       run = rep(run, T),
		       phi = rep(paste("phi = ", phi), T)))
    run <- run + 1
  }
}

queue_plot <-
  ggplot(queue_df, aes(x = t, y = queue, group = run)) +
  geom_line(alpha = 0.2, size = 0.2) +
  facet_wrap(. ~ phi) +  # facet_grid(rows = vars(phi)) +
  scale_x_continuous(breaks = c(1, 100, 200, 300)) +
  scale_y_continuous(breaks = c(0, 50, 100, 150)) +
  xlab("hours open") +
  ylab("queue size") +
  ggtheme_tufte() +
  theme(panel.spacing.y = unit(4, "lines")) +
  theme(legend.position = "none")
queue_plot
```

As can be seen in the plot, the queue not growing out of control is very sensitive to the average service rate per hour.  At an average rate of five cusotmers served per hour (matching the average customer intake), the queue quickly grows out of control.  With as few as five and a half customers served per hour, on average, it becomes stable long term; with seven customers served per hour, things settle down considerably.  When the queue goes up to 50 people, as it does with $\phi = 0.0055$, wait times are over ten hours.  Because of the cumulative nature of queues, a high server capacity is required to deal with spikes in customer arrival.

## Stationary distributions

In the example on fishes, where 1 represented a pike and 0 a perch, we
assumed the Markov process $Y$ was governed by

$$
\begin{array}{rcl}
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 1] & = & 0.20
\\[4pt]
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 0] & = & 0.05
\end{array}
$$

Rewriting as a probability mass function,

$$
p_{Y_{t + 1} \mid Y_t}(j \mid i) = \theta_{i, j},
$$

where $\theta_{i, j}$ is the probabiltiy of a transtion to state $j$
given that the process is in state $j$.  For the pike and perch
example,

$$
\begin{array}{rcl}
\theta_{1, 1} & = & 0.20
\\
\theta_{1, 2} & = & 0.80
\\ \hline
\theta_{2, 1} & = & 0.05
\\
\theta_{2, 2} & = & 0.95.
\end{array}
$$

These numbers are normally displayed in the form of a *transition
matrix*, which records the transitions out of each state as a row,
with the column indicating the target state,

$$
\theta =
\begin{bmatrix}
0.20 & 0.80 \\
0.05 & 0.95
\end{bmatrix}
$$

The first row of this transition matrix is $(0.20, 0.80)$ and the
second row of which is $(0.05, 0.95)$.^[Transition matrices for Markov
chains are called *stochastic matrices*, because they have
non-negative entries with rows that sum to one.] Rows of transition
matrices will always have non-negative entries and sum to one.^[Such
rows are known as *unit simplexes* and matrices in which every row is
a unit simplex is said to be a *stochastic matrix.* Transition
matrices for finite-state Markov chains are always stochastic
matrices.]

Now let's take a really long run of the chain with $T = 1\,000\,000$
fish to get a precise estimate of the long-run proportion of pike.

```{r}
set.seed(1234)
T <- 1e6
y <- rep(NA, M)
for (k in 0:1) {
  y[1] <- k
  for (t in 2:T) {
    y[t] <- rbinom(1, 1, ifelse(y[t - 1] == 1, 0.2, 0.05))
  }
  printf("initial state = %1f; simulated proportion of pike = %4.3f\n",
         k, sum(y) / T)
}
```

The initial state doesn't seem to matter. That's because the rate of
5.9% pike forms what is known as a stationary distribution. More
formally, let $\pi = (0.059, 1 - 0.059)$ and note that^[In matrix
notation, if $\pi$ is considered a row vector, then $$\pi = \theta \, \pi.$$]

$$
\pi_i = \sum_{j = 1}^2 \pi_j \times \theta_{j, i}.
$$

If $\pi$ satisfies this formula, then it is said to be the *stationary
distribution* for $\theta.$

A Markov chain is said to be *stationary* if

$$
p_{Y_t, \ldots, Y_{t + n}}(u_1, \ldots, u_n)
\ = \
p_{Y_{t + m}, \ldots, Y_{t + m + n}}(u_1, \ldots, u_n)
$$

holds for all $n,$ $m,$ and $u_1, \ldots, u_n$. In a stationary time
series, a sequence $u_1, \ldots, u_n$ has the same probability (or
density) at every point in time.

If a Markov chain has a stationary distribution $\pi$ and the initial
distribution of $Y_1$ is also $\pi$, then it is stationary.

## Convergence of non-stationary Markov chains

In practice, none of the Markov chains we employ in calculations will
be stationary for the simple reason that we don't know the stationary
distribution ahead of time and thus cannot draw $Y_1$ from it.^[In the
finite case, we actually can calculate it either through simulation or
as the eigenvector of the transition matrix with eigenvalue one (which
is guaranteed to exist). An eigenvector of a matrix is a row vector
$\pi$ such that $$c \times \pi = \theta \, \pi,$$ where $c$ is the
eigenvalue. This is why Google's PageRank algorithm is sometimes
jokingly referred to as "billion dollar eigenvector." One way to
calculate the relevant eigenvector of a stochastic matrix is by
raising it to a power, starting from any non-degenerate initial
simplex vector $\lambda$, $$\lim_{n \rightarrow \infty} \lambda \,
\theta^n = \pi.$$ Each $$\theta^n = \underbrace{\theta \times \theta
\times \cdots \times \theta}_{\textstyle n \ \mbox{times}}$$ is a transition
matrix corresponding to taking $n$ steps in the original transition
matrix $\theta$.]

But,
all of the Markov chains we will employ will have the property that
when run long enough, the distribution of elements in the chain will
approach the stationary distribution. In symbols, this means that if
we have a Markov chain for which $\pi$ is a stationary distribution,
then

$$
\lim_{t \rightarrow \infty} \
p_{Y_t}(u)
\rightarrow
\mbox{categorical}(u \mid \pi).
$$

Given a single simulation

$$
y^{(1)}
\ = \
y^{(1)}_1, y^{(1)}_2, \ldots, y^{(1)}_T
$$

we estimate $\pi$ using the frequencies in the simulated chain
$y^{(1)}$.  As usual, each entry $\pi_i$ is just the proportion of
simulated values that are equal to $i$.

$$
\hat{\pi}_i
=
\frac{1}{T} \sum_{t = 1}^T \mathrm{I}[y_t^{(1)} = i]
$$


What we need to know is conditions under which a Markov chain will
"forget" its initial state after many steps and converge to the
stationary distribution.